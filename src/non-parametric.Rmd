---
title: "Traditional non-parametric tests"
author: "Paul Sharpe and Andy Wills"
output:
  html_document:
    highlight: pygment
---

```{r setup, include=FALSE}
## DEVELOPERS: Uncomment one option, as appropriate
## Show only commands.
## knitr::opts_chunk$set(echo = TRUE, message = FALSE, results='hide', fig.keep = 'none', comment=NA)
## Mann-Whitney based on https://stackoverflow.com/questions/43033884/r-mann-whitney-u-test-output-like-in-spss
## For Kruskal-Wallis see http://www.sthda.com/english/wiki/kruskal-wallis-test-in-r
## Show commands and output.
knitr::opts_chunk$set(echo = TRUE, comment=NA, cache = FALSE)
library(pander)
```

## Contents

- [Introduction](#intro)

- [Getting started](#start)

- [Wilcoxon rank-sum test](#wilcox)

- [What about Mann-Whitney?](#mw)

- [Exercise 1](#ex1)

- [Kruskal-Wallis H test](#kruskal-wallis)

- [Exercise 2](#ex2)

<a name="intro"></a>

## Introduction

This worksheet covers the Wilcoxon rank-sum test, which is an alternative to the [between-subjects t-test](evidence.html#bs-ttest), and the Kruskal-Wallis H test, which is an alternative to the [between-subjects one-factor ANOVA](anova4.html#oneBS). 

The Wilcoxon rank-sum and Kruskal-Wallis H tests are both  _non-parametric_ tests. This means they make fewer assumptions about your data than do standard _parametric_ tests (such as t-tests, and ANOVA). Specifically, where your sample size is small, parametric tests assume that your population is approximately [normally distributed](https://ajwills72.github.io/critical-thinking/distributions-samples.pdf). However, it's  important to realise that as your sample size increases, parametric tests make fewer and fewer assumptions about your population distribution, due to the [central limit theorem](https://ajwills72.github.io/critical-thinking/distributions-samples.pdf). It's also important to realise that parametric tests have greater [statistical power](power.html) than non-parametric tests, so we should use parametric tests when their assumptions are met. 

Putting this all together, there's **a relatively small set of situations where it makes sense to use a non-parametric test** such as the Wilcoxon rank-sum or Kruskal-Wallis H. These are when:

1. Your sample size is small (N < 30 per group) **and**,
1. you do not know whether the population distribution is approximately normal **and**
1. you have reason to expect the effect size will be large (d > 1)

For example, you wouldn't use an non-parametric test on a small sample of IQ scores, because IQ is known to normally distributed. The point about effect size follows from the other two - if your sample size is small, you will only be able to detect large effects - see the [statistical power](power.html) worksheet. 

**Where's the Bayes Factor?** The Wilcoxon rank-sum and Kruskal-Wallis are traditional tests, in the sense that they give us a p-value rather than a Bayes Factor. As we have previously covered, [p-values are widely misinterpreted by psychologists](evidence.html#p-wrong), and can never provide evidence for the null hypothesis. For this reason, we have generally advised that you instead use the Bayesian equivalents of these tests - such as [Bayesian t-tests](evidence.html#bayes-t), [Bayesian ANOVA](anova1.html#anovaWS), and [Bayesian chi-square](chi.html#evidence). However, it is not straight forward to calculate Bayesian equivalents of the Mann-Whitney and Kruskal-Wallis tests in R at the moment. So, in this case, we'll stick to the traditional tests. 

<a name="start"></a>

## Getting started

To prepare for this worksheet:

1. Open the `rminr-data` project we used [previously](preproc.html#load).

1. If you don't see a folder named `going-further`, it means you created your project _before_ the data required for this worksheet was added to the `rminr-data` git repository. You can get the latest files by asking git to "`pull`" the repository. Select the `Git` tab, which is located in the row of tabs which includes the `Environment` tab. Click the `Pull` button with a downward pointing arrow. A window will open showing the files which have been pulled from the repository. Close the `Git pull` window.

1. Open the `Files` tab. The `going-further` folder should contain the file `picture-naming-preproc.csv` and `music-emotion-preproc.csv`.

1. Create a script named `non-parametric.R` in the `rminr-data` folder (the folder above `going-further`). Add the code to this script as you work through each section of the worksheet.

<a name="wilcox"></a>

## Wilcoxon rank-sum test

### Loading and preprocessing data

We'll demonstrate the Wilcoxon rank-sum test using data from an experiment which evaluated childrenâ€™s language development using the Words in Game (WinG) test. WinG consists of a set of picture cards that are used in four tests: noun comprehension, noun production, predicate comprehension, and predicate production. The Italian and English versions of the WinG cards use different pictures to depict the associated concepts. The experiment tested whether English-speaking children aged approximately 30 months produce different responses for the two sets of cards.

We start by loading the data:

```{r load, message=FALSE, class.source = 'numberLines lineAnchors'}
rm(list = ls()) # clear the environment
library(tidyverse)
wing_preproc <- read_csv('going-further/picture-naming-preproc.csv')
```

**Explanation of commands:**

These commands should be familiar from previous worksheets. Line 1 clears the environment. Line 2 loads the `tidyverse` package. Line 3 reads the data. 

The first few lines of `wing_preproc` look like this:

```{r, echo=FALSE}
wing_preproc %>% head(12) %>% pander(split.table = Inf)
```
Our test scores are currently in _wide_ format (lots of columns, few rows), but R generally requires data to be in _long_ format (lots of rows, few columns). This means we first have to make the data frame longer, so we can calculate summary statistics.

```{r pivot}
# wide to long
task_by_subj <- wing_preproc %>%
  pivot_longer(cols = c(nc, np, pc, pp),
               names_to = 'task',
               values_to = 'correct') %>%
  select(subj, gender, cards, task, correct)
```

**Explanation of command:**

In the [Within-subject differences worksheet](anova1.html#pivot), you learned how to use `pivot_wider()` to widen long data frames. The `pivot_longer()` command does the reverse -- it lengthens wide data frames. `cols = c(nc, np, pc, pp)` selects the columns we want to pivot. Each value in these columns is added to a row in a new column called `correct` (`values_to = 'correct'`). In the same row, a new column `task` is set to the name of the column which the value came from (`names_to = 'task'`). All of the values in the other columns are duplicated for each row. We [select](preproc.html#select) just the columns we want for our table of descriptive statistics.

The first few rows of `task_by_subj` look like this:

```{r, echo=FALSE}
task_by_subj %>% head() %>% pander()
```

In the next section, we are going to compare English and Italian on the noun comprehension task. So, we filter the data (which contains all four tasks) to include just that task. We also remove any missing data (recorded as `NA`). 

```{r}
# Filter
nc_include <- task_by_subj %>% filter(task == 'nc') %>% drop_na()
```

**Explanation of command**: The `filter` command should be familiar from many previous worksheets. `drop_na()` is explained in more detail in the [preprocessing scales](preproc-scales.html#missing) worksheet, but basically it just removes any row that contains an `NA` in it.


<a name="summary"></a>

### Calculating descriptive statistics

When we report non-parametric tests, we normally report the median (rather than the mean) as our descriptive statistic. This makes practical sense, because the mean can be misleading when the distribution is skewed and, if we have chosen to do a non-parametric test, we are (presumably) uncertain whether the distribution is skewed or not.

```{r}
# summary statistics
nc_summary <- nc_include %>%
  group_by(cards) %>%
  summarise(median = median(correct))
nc_summary
```

**Explanation of commands:** These commands should be familiar from several previous worksheets. We group the data by `cards`, and use `summarise`, to calculate the `median()` score for each group.

### Calculating the Wilcoxon rank-sum test

The Wilcoxon rank sum test is a non-parametric equivalent of a between-subjects t-test. It works by ranking all of the scores in the two groups, adding the ranks in each group, and comparing these "summed ranks" to determine if they differ.

We'll run a Wilcoxon rank-sum test to see if there were any significant differences between scores for the Italian and English cards on the noun comprehension (`nc`) task.

```{r mw-nc}
# Mann-Whitney U for noun comprehension
wilcox.test(correct ~ cards, nc_include)
```

```{r mw-nc-hidden,echo=FALSE,results='hide', message=FALSE, warning=FALSE}
nc_u  <- wilcox.test(correct ~ cards, nc_include)
```

**Explanation of commands:**

The command `wilcox.test(correct ~ cards, nc_include)` runs the test to compare the `correct` scores for the Italian and English `cards`.

**Explanation of output:**

The phrase `with continuity correction` is a technical detail that can be safely ignored. If you're curious, you can read more in the help file, by typing `?wilcoxon.test` into the console.

The phrase `correct by cards` reminds you that you compared the values in `correct` between the levels in the `cards` factor. A `p` value of less than .05 is generally considered by psychologists to be evidence that the two groups are different. 

The phrase `alternative hypothesis: true location shift is not equal to 0` can be safely ignored, as it's just another (rather obscure) way of saying that you are testing whether the two groups are different.

The warning `cannot compute exact p-value with ties` lets you know that the method used to calculate _p_ will not be exact, because some items in the Italian and English scores had identical rankings.

We now have all of the information we need to report the results. For the noun comprehension task, there was no significant difference in accuracy between the Italian (_Mdn_ = `r nc_summary[nc_summary$cards == 'italian', 'median']`) and English (_Mdn_ = `r nc_summary[nc_summary$cards == 'english', 'median']`) cards _W_ = `r nc_u$statistic`, _p_ = `r round(nc_u$p.value, 2)`.




<a name="mw"></a>

## What about Mann-Whitney?

In some journal articles, you may see a non-parametric test called a "Mann-Whitney U". This is exactly the same test as computed in the Wilcoxon rank-sum test above, just with a different name (and represented by a U rather than a W). 


<a name="ex1"></a>

## Exercise 1

Calculate summary statistics and the Wilxocon rank-sum for the noun production task. Your results should look like this:

```{r ex1, echo=FALSE}
np_include <- task_by_subj %>% filter(task == 'np') %>% drop_na()
np_include <- np_include %>% mutate(rank = rank(correct))
np_include %>%
  group_by(cards) %>%
  summarise(n = n(),
            median = median(correct),
            mean_rank = mean(rank),
            sum_rank = sum(rank))
wilcox.test(correct ~ cards, np_include)
```

**Copy the R code you used for this exercise into PsycEL.**

<a name="kruskal-wallis"></a>

## Kruskal-Wallis H test

The Kruskal-Wallis H test is a non-parametric equivalent of a one-way between subjects ANOVA. It extends the Mann-Whitney test to situations where there are more than two groups.

We'll demonstrate this test using data from a study which compared emotion regulation strategies between fans of mainstream (control group), goth, metal and emo music. Participants were measured using the Emotion Regulation Strategies for Artistic Creative Activities Scale (ERS-ACA), an 18 item inventory, with each item scored from 1 ('strongly disagree') to 5 ('strongly agree'). The ERS-ACA gives an overall measure of the strategy people use to regulate their emotions when they engage in artistic, creative activities, and scores on three strategy sub-scales; avoidance, approach and self-development.

We start by loading the data:

```{r load-ers}
# Kruskal-Wallis H test
ers_l <- read_csv('going-further/music-emotion-preproc.csv', col_types = 'fffd')
```

**Explanation of command:**

This data has already undergone some preprocessing and is in long format. We use `col_types = 'fffd'` to set the first three columns as factors, and the fourth column as a number with decimal places.

The first few lines of `ers_l` look like this:

```{r, echo=FALSE}
ers_l %>% head(8) %>% pander()
```

Like the Mann-Whitney test, the Kruskal-Wallis test works on ranked data. We'll start by generating some summary statistics for the 'approach' subscale.

```{r k-w-summary, class.source = 'numberLines lineAnchors'}
approach <- ers_l %>% filter(ers == 'approach')
approach <- approach %>% mutate(rank = rank(score))
approach_summary <- approach %>%
  group_by(subculture) %>%
  summarise(n = n(),
            median = median(score, na.rm = TRUE),
            mean_rank = mean(rank),
            sum_rank = sum(rank))
approach_summary
```

**Explanation of commands:**

Line 1 filters the data to only include measurements for the 'approach' subscale. The second line ranks the scores for all participants. Lines 3-8 are very similar to the summary statistics we generated for the Mann-Whitney test. In this case we group by music `subculture`.

**Explanation of output:**

The differences between groups look quite small, the largest being between `Mainstream` and `Emo`.

We can now run the Kruskal-Wallis test:

```{r k-w}
kw <- kruskal.test(score ~ subculture, data = approach)
kw
```

**Explanation of commands:**

The command `kruskal.test(score ~ subculture, data = approach)` runs the test to compare the ERS-ACA `score` scores for the four groups in `subculture`.

**Explanation of output:**

The string `score by subculture` reminds you that you compared the values in `score` between the levels in the `subculture` factor. The Kruskal-Wallis _H_ statistic is `r kw$statistic` and is derived from a chi-square distribution, using a calculation similar to the chi-squared test introduced in [the Relationships worksheet](chi.html). The degrees of freedom is one less than the number of groups, in this case `r kw$parameter`. The `p` value tells us whether there was  a significant difference between the medians in any of the four groups.

There was no significant difference in approach style between the mainstream (_Mdn_ = `r round(approach_summary[approach_summary$subculture == 'Mainstream', 'median'], 2)`), goth (_Mdn_ = `r round(approach_summary[approach_summary$subculture == 'Goth', 'median'], 2)`), metal (_Mdn_ = `r round(approach_summary[approach_summary$subculture == 'Metal', 'median'], 2)`) and emo (_Mdn_ = `r round(approach_summary[approach_summary$subculture == 'Emo', 'median'], 2)`) groups (_H_ = `r round(kw$statistic, 2)`, _p_ = `r round(kw$p.value, 2)`).

<a name="ex2"></a>

## Exercise 2

Calculate summary statistics and Kruskal-Wallis H for the self-development emotional response subscale of the ERS-ACA. Your results should look like this:

```{r ex2, echo=FALSE}
development <- ers_l %>% filter(ers == 'development')
development <- development %>% mutate(rank = rank(score))
development %>%
  group_by(subculture) %>%
  summarise(n = n(),
            median = median(score, na.rm = TRUE),
            mean_rank = mean(rank),
            sum_rank = sum(rank))
kruskal.test(score ~ subculture, data = development)
```

**Copy the R code you used for this exercise into PsycEL.**

___

This material is distributed under a [Creative Commons](https://creativecommons.org/) licence. CC-BY-SA 4.0.
